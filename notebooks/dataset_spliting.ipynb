{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-18T11:40:01.597636Z",
     "start_time": "2024-06-18T11:39:52.933119Z"
    }
   },
   "source": [
    "import logging\n",
    "from preprocessing.covid_dataset import CovidDataset\n",
    "from monai.data import DataLoader\n",
    "import monai\n",
    "from config.constants import (COVID_CASES_PATH, INFECTION_MASKS_PATH, SEED)\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from monai.visualize import plot_2d_or_3d_image, matshow3d, blend_images\n",
    "from pathlib import Path"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 13:39:58.165493: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-18 13:39:58.209186: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T11:40:01.605257Z",
     "start_time": "2024-06-18T11:40:01.599668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def load_images_from_path(path: str) -> list[str]:\n",
    "    logging.debug(f\"Loading images from {path}\")\n",
    "    return sorted([str(f) for f in Path(path).iterdir() if f.is_file() and f.suffix == '.gz'])\n",
    "\n",
    "images = load_images_from_path(\"../\" + COVID_CASES_PATH)\n",
    "print(images)"
   ],
   "id": "2a235a45a4d642b3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../Datasets/Zenodo/COVID-19-CT-Seg_20cases/coronacases_001.nii.gz', '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/coronacases_002.nii.gz', '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/coronacases_003.nii.gz', '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/coronacases_004.nii.gz', '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/coronacases_005.nii.gz', '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/coronacases_006.nii.gz', '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/coronacases_007.nii.gz', '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/coronacases_008.nii.gz', '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/coronacases_009.nii.gz', '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/coronacases_010.nii.gz', '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/radiopaedia_10_85902_1.nii.gz', '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/radiopaedia_10_85902_3.nii.gz', '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/radiopaedia_14_85914_0.nii.gz', '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/radiopaedia_27_86410_0.nii.gz', '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/radiopaedia_29_86490_1.nii.gz', '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/radiopaedia_29_86491_1.nii.gz', '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/radiopaedia_36_86526_0.nii.gz', '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/radiopaedia_40_86625_0.nii.gz', '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/radiopaedia_4_85506_1.nii.gz', '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/radiopaedia_7_85703_0.nii.gz']\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T11:40:01.631820Z",
     "start_time": "2024-06-18T11:40:01.606395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SPATIAL_SIZE = (32, 32, 32)\n",
    "NUM_RAND_PATCHES = 4\n",
    "LEVEL = -650\n",
    "WIDTH = 1500\n",
    "LOWER_BOUND_WINDOW_HRCT = LEVEL - (WIDTH // 2) \n",
    "UPPER_BOUND_WINDOW_HRCT = LEVEL + (WIDTH // 2)\n",
    "LOWER_BOUND_WINDOW_CBCT = 0\n",
    "UPPER_BOUND_WINDOW_CBCT = 255\n",
    "\n",
    "\n",
    "def get_hrct_transforms():\n",
    "    return monai.transforms.Compose(\n",
    "        [\n",
    "            monai.transforms.LoadImaged(keys=('img', 'mask'), image_only=True, ensure_channel_first=True),\n",
    "            monai.transforms.Orientationd(keys=('img', 'mask'), axcodes=\"PLI\"),\n",
    "            monai.transforms.ScaleIntensityRanged(keys=('img',), a_min=LOWER_BOUND_WINDOW_HRCT,\n",
    "                                                  a_max=UPPER_BOUND_WINDOW_HRCT, b_min=0.0, b_max=1.0, clip=True),\n",
    "            monai.transforms.RandCropByPosNegLabeld(keys=('img', 'mask'), label_key=\"mask\",\n",
    "                                                    spatial_size=SPATIAL_SIZE, pos=1, neg=1,\n",
    "                                                    num_samples=NUM_RAND_PATCHES, allow_smaller=True),\n",
    "            \n",
    "            monai.transforms.ToTensord(keys=(\"img\", \"mask\")),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def get_cbct_transforms():\n",
    "    return monai.transforms.Compose(\n",
    "        [\n",
    "            monai.transforms.LoadImaged(keys=('img', 'mask'), image_only=True, ensure_channel_first=True),\n",
    "            monai.transforms.Orientationd(keys=('img', 'mask'), axcodes=\"ALI\"),\n",
    "            monai.transforms.RandCropByPosNegLabeld(keys=('img', 'mask'), label_key=\"mask\",\n",
    "                                                    spatial_size=SPATIAL_SIZE, pos=1, neg=1,\n",
    "                                                    num_samples=NUM_RAND_PATCHES, allow_smaller=True),\n",
    "            monai.transforms.ScaleIntensityd(keys='img', minv=LOWER_BOUND_WINDOW_CBCT, maxv=UPPER_BOUND_WINDOW_CBCT),\n",
    "            monai.transforms.ToTensord(keys=(\"img\", \"mask\")),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def get_val_hrct_transforms():\n",
    "    return monai.transforms.Compose(\n",
    "        [\n",
    "            monai.transforms.LoadImaged(keys=('img', 'mask'), image_only=True, ensure_channel_first=True),\n",
    "            monai.transforms.Orientationd(keys=('img', 'mask'), axcodes=\"PLI\"),\n",
    "            monai.transforms.ScaleIntensityRanged(keys=('img',), a_min=LOWER_BOUND_WINDOW_HRCT,\n",
    "                                                  a_max=UPPER_BOUND_WINDOW_HRCT, b_min=0.0, b_max=1.0,\n",
    "                                                  clip=True),\n",
    "            monai.transforms.ToTensord(keys=(\"img\", \"mask\")),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def get_val_cbct_transforms():\n",
    "    return monai.transforms.Compose(\n",
    "        [\n",
    "            monai.transforms.LoadImaged(keys=('img', 'mask'), image_only=True, ensure_channel_first=True),\n",
    "            monai.transforms.Orientationd(keys=('img', 'mask'), axcodes=\"ALI\"),\n",
    "            monai.transforms.ScaleIntensityd(keys='img', minv=LOWER_BOUND_WINDOW_CBCT, maxv=UPPER_BOUND_WINDOW_CBCT),\n",
    "            monai.transforms.ToTensord(keys=(\"img\", \"mask\")),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "# Load images and masks\n",
    "logging.info(f\"Loading images from {COVID_CASES_PATH}\")\n",
    "images = load_images_from_path(\"../\" + COVID_CASES_PATH)\n",
    "labels = load_images_from_path(\"../\" + INFECTION_MASKS_PATH)\n",
    "\n",
    "# Convert images and masks to a list of dictionaries with keys \"img\" and \"mask\"\n",
    "data_dicts = np.array([{\"img\": img, \"mask\": mask} for img, mask in zip(images, labels)])\n",
    "logging.debug(data_dicts)\n",
    "\n",
    "print(data_dicts)\n",
    "shuffler = np.random.RandomState(1)\n",
    "shuffler.shuffle(data_dicts)\n",
    "data_dicts = list(data_dicts)\n",
    "print()\n",
    "print(type(data_dicts))\n",
    "print()\n",
    "print(data_dicts)\n",
    "print(SEED)\n",
    "\n",
    "# Split the data into training (70%), validation (10%), and test sets (20%)\n",
    "test_split = int(len(data_dicts) * 0.2)\n",
    "val_split = int(len(data_dicts) * 0.1)\n",
    "\n",
    "train_paths = data_dicts[test_split + val_split:]\n",
    "val_paths = data_dicts[test_split:test_split + val_split]\n",
    "test_paths = data_dicts[:test_split]"
   ],
   "id": "5c95a28f74e4e092",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/coronacases_001.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/coronacases_001.nii.gz'}\n",
      " {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/coronacases_002.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/coronacases_002.nii.gz'}\n",
      " {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/coronacases_003.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/coronacases_003.nii.gz'}\n",
      " {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/coronacases_004.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/coronacases_004.nii.gz'}\n",
      " {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/coronacases_005.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/coronacases_005.nii.gz'}\n",
      " {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/coronacases_006.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/coronacases_006.nii.gz'}\n",
      " {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/coronacases_007.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/coronacases_007.nii.gz'}\n",
      " {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/coronacases_008.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/coronacases_008.nii.gz'}\n",
      " {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/coronacases_009.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/coronacases_009.nii.gz'}\n",
      " {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/coronacases_010.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/coronacases_010.nii.gz'}\n",
      " {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/radiopaedia_10_85902_1.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/radiopaedia_10_85902_1.nii.gz'}\n",
      " {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/radiopaedia_10_85902_3.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/radiopaedia_10_85902_3.nii.gz'}\n",
      " {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/radiopaedia_14_85914_0.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/radiopaedia_14_85914_0.nii.gz'}\n",
      " {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/radiopaedia_27_86410_0.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/radiopaedia_27_86410_0.nii.gz'}\n",
      " {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/radiopaedia_29_86490_1.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/radiopaedia_29_86490_1.nii.gz'}\n",
      " {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/radiopaedia_29_86491_1.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/radiopaedia_29_86491_1.nii.gz'}\n",
      " {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/radiopaedia_36_86526_0.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/radiopaedia_36_86526_0.nii.gz'}\n",
      " {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/radiopaedia_40_86625_0.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/radiopaedia_40_86625_0.nii.gz'}\n",
      " {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/radiopaedia_4_85506_1.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/radiopaedia_4_85506_1.nii.gz'}\n",
      " {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/radiopaedia_7_85703_0.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/radiopaedia_7_85703_0.nii.gz'}]\n",
      "\n",
      "<class 'list'>\n",
      "\n",
      "[{'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/coronacases_004.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/coronacases_004.nii.gz'}, {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/radiopaedia_36_86526_0.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/radiopaedia_36_86526_0.nii.gz'}, {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/coronacases_007.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/coronacases_007.nii.gz'}, {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/radiopaedia_10_85902_1.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/radiopaedia_10_85902_1.nii.gz'}, {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/coronacases_003.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/coronacases_003.nii.gz'}, {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/radiopaedia_29_86490_1.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/radiopaedia_29_86490_1.nii.gz'}, {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/coronacases_005.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/coronacases_005.nii.gz'}, {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/radiopaedia_40_86625_0.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/radiopaedia_40_86625_0.nii.gz'}, {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/coronacases_008.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/coronacases_008.nii.gz'}, {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/coronacases_002.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/coronacases_002.nii.gz'}, {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/radiopaedia_27_86410_0.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/radiopaedia_27_86410_0.nii.gz'}, {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/coronacases_001.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/coronacases_001.nii.gz'}, {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/radiopaedia_7_85703_0.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/radiopaedia_7_85703_0.nii.gz'}, {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/radiopaedia_4_85506_1.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/radiopaedia_4_85506_1.nii.gz'}, {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/coronacases_010.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/coronacases_010.nii.gz'}, {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/radiopaedia_29_86491_1.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/radiopaedia_29_86491_1.nii.gz'}, {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/coronacases_009.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/coronacases_009.nii.gz'}, {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/radiopaedia_14_85914_0.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/radiopaedia_14_85914_0.nii.gz'}, {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/radiopaedia_10_85902_3.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/radiopaedia_10_85902_3.nii.gz'}, {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/coronacases_006.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/coronacases_006.nii.gz'}]\n",
      "1\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T11:40:01.647084Z",
     "start_time": "2024-06-18T11:40:01.632973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a dataset and a dataloader for the training set\n",
    "train_dataset = CovidDataset(volumes=train_paths, hrct_transform=get_hrct_transforms(), cbct_transform=get_cbct_transforms())\n",
    "train_loader = DataLoader(train_dataset, batch_size=1, num_workers=2)\n",
    "\n",
    "# Create a dataset and a dataloader for the validation set\n",
    "val_dataset = CovidDataset(volumes=val_paths, hrct_transform=get_val_hrct_transforms(), cbct_transform=get_val_cbct_transforms())\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, num_workers=2)\n",
    "\n",
    "# Create a dataset and a dataloader for the test set\n",
    "test_dataset = CovidDataset(volumes=test_paths, hrct_transform=get_val_hrct_transforms(), cbct_transform=get_val_cbct_transforms())\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, num_workers=2)"
   ],
   "id": "d33bb29a1f67e3a",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# create a funcion that takes a dataset an proves if it has only zeros in the mask. In that case throw an error. Also check for radiopaedia and coronacases in the path of the dataset. If there is one that it isn't throw an error\n",
    "def check_dataset(dataset):\n",
    "    radiopaedia = False\n",
    "    coronacases = False\n",
    "    for i, data in enumerate(dataset):\n",
    "        if np.unique(data[\"mask\"]).size == 1 and np.unique(data[\"mask\"])[0] == 0:\n",
    "            raise ValueError(\"The mask has only zeros\")\n",
    "\n",
    "        if \"radiopaedia\" in dataset.volumes[i][\"img\"]:\n",
    "            radiopaedia = True\n",
    "        if \"coronacases\" in dataset.volumes[i][\"img\"]:\n",
    "            coronacases = True\n",
    "\n",
    "    if not radiopaedia or not coronacases:\n",
    "        raise ValueError(\"There are no radiopaedia or coronacases in the dataset\")\n",
    "\n",
    "    return"
   ],
   "id": "fff39c197b266f46",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# test validation test\n",
    "check_dataset(val_dataset)"
   ],
   "id": "218aa8f0bbe3e89",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(val_dataset[0][\"img\"].shape)\n",
    "print(val_dataset[1][\"img\"].shape)"
   ],
   "id": "e1050b9f7534e274",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "val_dataset.volumes",
   "id": "c867fb7b54723bbd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# SHOW DATASET",
   "id": "4b5d736f00e83777"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T11:40:15.887944Z",
     "start_time": "2024-06-18T11:40:15.878979Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def draw_volumes(dataloader, dataset):\n",
    "     for i, data in enumerate(dataloader):\n",
    "        volume = dataset.volumes[i]['img'].split('/')[-1].split('.')[0]\n",
    "        Path(f\"images/{volume}\").mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"Processing volume {i}: {volume}\")\n",
    "        print(f\"img shape: {data['img'].shape}\")\n",
    "        for j in range(data[\"img\"].shape[0]):\n",
    "            print(f\"Processing subvolume {j+1}\")\n",
    "            \n",
    "            img = data[\"img\"][j]\n",
    "            seg = data[\"mask\"][j]\n",
    "            print(f\"img shape: {img.shape}\")\n",
    "            blended_img = blend_images(img, seg, alpha=0.5, cmap=\"hsv\", rescale_arrays=True)\n",
    "            blended_img = (blended_img - blended_img.min()) / (blended_img.max() - blended_img.min())\n",
    "            print(f\"blended_img shape: {blended_img.shape}\")\n",
    "            fig = plt.figure(figsize=(30, 30))\n",
    "            plt.title(f\"subvolume{j}\")\n",
    "            print(blended_img.shape[-1])\n",
    "            for k in range(blended_img.shape[-1]):\n",
    "                print(f\"Processing slice {k+1}\")\n",
    "                ax = fig.add_subplot(16, 16, k+1)\n",
    "                ax.imshow(torch.moveaxis(blended_img[:, :, :, k], 0, -1))\n",
    "                ax.axis('off')\n",
    "            plt.savefig(f\"images/{volume}/{j+1}.png\")\n",
    "            plt.close()\n",
    "             \n",
    "def draw_volumes2(dataloader, dataset):\n",
    "     for i, data in enumerate(dataloader):\n",
    "        volume = dataset.volumes[i]['img'].split('/')[-1].split('.')[0]\n",
    "        Path(f\"images/{volume}\").mkdir(parents=True, exist_ok=True)\n",
    "        print(f\"Processing volume {i}: {volume}\")\n",
    "        print(f\"img shape: {data['img'].shape}\")\n",
    "        fig = plt.figure()\n",
    "        print(data[\"img\"].shape)\n",
    "        matshow3d(\n",
    "            data[\"img\"][0][0],\n",
    "            fig=fig,\n",
    "            figsize=(20, 20),\n",
    "            frame_dim=-1,\n",
    "            cmap=\"gray\"\n",
    "        )\n",
    "        plt.savefig(f\"images/{volume}/{i}.png\")\n",
    "        plt.close()"
   ],
   "id": "629f4635bd84a19c",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T11:40:25.038139Z",
     "start_time": "2024-06-18T11:40:16.643523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Show validation volumes\n",
    "draw_volumes2(val_loader, val_dataset)"
   ],
   "id": "8bd740ce837ffaa5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suuuusuuuu2\n",
      "\n",
      "volume: {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/radiopaedia_29_86490_1.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/radiopaedia_29_86490_1.nii.gz'}volume: {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/coronacases_003.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/coronacases_003.nii.gz'}\n",
      "\n",
      "Processing volume 0: coronacases_003\n",
      "img shape: torch.Size([1, 1, 512, 512, 200])\n",
      "torch.Size([1, 1, 512, 512, 200])\n",
      "Processing volume 1: radiopaedia_29_86490_1\n",
      "img shape: torch.Size([1, 1, 630, 630, 42])\n",
      "torch.Size([1, 1, 630, 630, 42])\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib\n",
    "matplotlib.__version__"
   ],
   "id": "10eba61c40e41c8c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-18T11:40:10.269131Z",
     "start_time": "2024-06-18T11:40:06.670208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i, data in enumerate(val_loader):\n",
    "    print(data[\"img\"].shape)\n",
    "    print(data[\"mask\"].shape)\n",
    "    break"
   ],
   "id": "177eb0b8fafa0ebd",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suuuu\n",
      "volume: {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/coronacases_003.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/coronacases_003.nii.gz'}\n",
      "suuuu2\n",
      "volume: {'img': '../Datasets/Zenodo/COVID-19-CT-Seg_20cases/radiopaedia_29_86490_1.nii.gz', 'mask': '../Datasets/Zenodo/Infection_Mask/radiopaedia_29_86490_1.nii.gz'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 512, 512, 200])\n",
      "torch.Size([1, 1, 512, 512, 200])\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "fc42ca64da970db1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
