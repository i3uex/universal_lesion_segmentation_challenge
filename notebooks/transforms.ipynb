{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-16T11:12:52.546305Z",
     "start_time": "2024-07-16T11:12:52.542944Z"
    }
   },
   "source": [
    "import logging\n",
    "from monai.data import DataLoader\n",
    "import monai\n",
    "from config.constants import (ZENODO_COVID_CASES_PATH, ZENODO_INFECTION_MASKS_PATH)\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from monai.visualize import plot_2d_or_3d_image, matshow3d, blend_images\n",
    "from pathlib import Path\n",
    "from utils.helpers import load_images_from_path"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T11:12:53.631832Z",
     "start_time": "2024-07-16T11:12:53.615580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SPATIAL_SIZE = (32, 32, 32)\n",
    "NUM_RAND_PATCHES = 4\n",
    "LEVEL = -650\n",
    "WIDTH = 1500\n",
    "LOWER_BOUND_WINDOW_HRCT = LEVEL - (WIDTH // 2) \n",
    "UPPER_BOUND_WINDOW_HRCT = LEVEL + (WIDTH // 2)\n",
    "LOWER_BOUND_WINDOW_CBCT = 0\n",
    "UPPER_BOUND_WINDOW_CBCT = 255\n",
    "SEED = 33\n",
    "\n",
    "\n",
    "print(LOWER_BOUND_WINDOW_HRCT)\n",
    "print(UPPER_BOUND_WINDOW_HRCT)\n",
    "def get_hrct_transforms():\n",
    "    return monai.transforms.Compose(\n",
    "        [\n",
    "            monai.transforms.LoadImaged(keys=('img', 'mask'), image_only=True, ensure_channel_first=True),\n",
    "            monai.transforms.Orientationd(keys=('img', 'mask'), axcodes=\"PLI\"),\n",
    "            monai.transforms.ThresholdIntensityd(keys=(\"img\",), threshold=LOWER_BOUND_WINDOW_HRCT, above=False, cval=LOWER_BOUND_WINDOW_HRCT),\n",
    "            monai.transforms.ThresholdIntensityd(keys=(\"img\",), threshold=UPPER_BOUND_WINDOW_HRCT, above=True, cval=UPPER_BOUND_WINDOW_HRCT),\n",
    "            monai.transforms.ScaleIntensityRanged(keys=('img',), a_min=LOWER_BOUND_WINDOW_HRCT,\n",
    "                                                  a_max=UPPER_BOUND_WINDOW_HRCT, b_min=0.0, b_max=1.0, clip=True, allow_missing_keys=True),\n",
    "            monai.transforms.RandCropByPosNegLabeld(keys=('img', 'mask'), label_key=\"mask\",\n",
    "                                                    spatial_size=SPATIAL_SIZE, pos=1, neg=1,\n",
    "                                                    num_samples=NUM_RAND_PATCHES, allow_smaller=True),\n",
    "            monai.transforms.ToTensord(keys=(\"img\", \"mask\")),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def get_cbct_transforms():\n",
    "    return monai.transforms.Compose(\n",
    "        [\n",
    "            monai.transforms.LoadImaged(keys=('img', 'mask'), image_only=True, ensure_channel_first=True),\n",
    "            monai.transforms.Orientationd(keys=('img', 'mask'), axcodes=\"ALI\"),\n",
    "            monai.transforms.RandCropByPosNegLabeld(keys=('img', 'mask'), label_key=\"mask\",\n",
    "                                                    spatial_size=SPATIAL_SIZE, pos=1, neg=1,\n",
    "                                                    num_samples=NUM_RAND_PATCHES, allow_smaller=True),\n",
    "            monai.transforms.ScaleIntensityd(keys='img', minv=0.0, maxv=1.0),\n",
    "            monai.transforms.ToTensord(keys=(\"img\", \"mask\")),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def get_val_hrct_transforms():\n",
    "    return monai.transforms.Compose(\n",
    "        [\n",
    "            monai.transforms.LoadImaged(keys=('img', 'mask'), image_only=True, ensure_channel_first=True),\n",
    "            monai.transforms.Orientationd(keys=('img', 'mask'), axcodes=\"PLI\"),\n",
    "            monai.transforms.ThresholdIntensityd(keys=(\"img\",), threshold=LOWER_BOUND_WINDOW_HRCT, above=True, cval=LOWER_BOUND_WINDOW_HRCT),\n",
    "            monai.transforms.ThresholdIntensityd(keys=(\"img\",), threshold=UPPER_BOUND_WINDOW_HRCT, above=False, cval=UPPER_BOUND_WINDOW_HRCT),\n",
    "            monai.transforms.ScaleIntensityd(keys='img', minv=0.0, maxv=1.0),\n",
    "            monai.transforms.ToTensord(keys=(\"img\", \"mask\")),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def get_val_cbct_transforms():\n",
    "    print(\"asdfas\")\n",
    "    return monai.transforms.Compose(\n",
    "        [\n",
    "            monai.transforms.LoadImaged(keys=('img', 'mask'), image_only=True, ensure_channel_first=True),\n",
    "            monai.transforms.Orientationd(keys=('img', 'mask'), axcodes=\"ALI\"),\n",
    "            monai.transforms.ScaleIntensityd(keys='img', minv=0.0, maxv=1.0),\n",
    "            monai.transforms.ToTensord(keys=(\"img\", \"mask\")),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def get_raw_transforms():\n",
    "    return monai.transforms.Compose(\n",
    "        [\n",
    "            monai.transforms.LoadImaged(keys=('img', 'mask'), image_only=False, ensure_channel_first=True),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def load_radiopaedia_from_path(path: str) -> list[str]:\n",
    "    return sorted([str(f) for f in Path(path).iterdir() if f.suffix == '.gz' and f.is_file()]) # and 'radiopaedia' in f.stem])\n",
    "\n",
    "class CovidDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, volumes, hrct_transform=None, cbct_transform=None):\n",
    "        self.volumes = volumes\n",
    "        self.hrct_transform = hrct_transform\n",
    "        self.cbct_transform = cbct_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.volumes)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        volume = self.volumes[index]\n",
    "\n",
    "        if \"coronacases\" in volume[\"img\"]:\n",
    "            return self.hrct_transform(volume)\n",
    "        else:\n",
    "            return self.cbct_transform(volume)\n",
    "        "
   ],
   "id": "99b8b39e7c9dc268",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1400\n",
      "100\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T11:12:57.541841Z",
     "start_time": "2024-07-16T11:12:57.537401Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load images and masks\n",
    "logging.info(f\"Loading images from {ZENODO_COVID_CASES_PATH}\")\n",
    "images = load_radiopaedia_from_path(\"../\" + ZENODO_COVID_CASES_PATH)\n",
    "labels = load_radiopaedia_from_path(\"../\" + ZENODO_INFECTION_MASKS_PATH)\n",
    "\n",
    "\n",
    "# Convert images and masks to a list of dictionaries with keys \"img\" and \"mask\"\n",
    "data_dicts = np.array([{\"img\": img, \"mask\": mask} for img, mask in zip(images, labels)])\n",
    "logging.debug(data_dicts)\n",
    "\n",
    "# shuffler = np.random.RandomState(SEED)\n",
    "# shuffler.shuffle(data_dicts)\n",
    "# data_dicts = list(data_dicts)"
   ],
   "id": "53e8485494a5e916",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T11:12:58.923922Z",
     "start_time": "2024-07-16T11:12:58.904730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load images and masks\n",
    "mask_range = (\"0255\", \"0304\")\n",
    "images_path = \"../Datasets/COVID19_1110/studies/\"\n",
    "labels_path = \"../Datasets/COVID19_1110/masks/\"\n",
    "# for all subdirectories in the images_path, load the images in range mask_range\n",
    "# the images are names like study_0255.nii.gz and we have to load the images in the range mask_range\n",
    "images = []\n",
    "for subdir in Path(images_path).iterdir():\n",
    "    if subdir.is_dir():\n",
    "        for f in subdir.iterdir():\n",
    "            # take name of the file and split it by \"_\" and clean the extension .nii.gz and then check if the number is in the range\n",
    "            if f.is_file() and mask_range[0] <= f.stem.split(\"_\")[1].split(\".\")[0] <= mask_range[1]:\n",
    "                images.append(str(f))\n",
    "\n",
    "labels = load_images_from_path(labels_path)\n",
    "\n",
    "# # Convert images and masks to a list of dictionaries with keys \"img\" and \"mask\"\n",
    "data_dicts1 = np.array([{\"img\": img, \"mask\": mask} for img, mask in zip(images, labels)])\n",
    "# logging.debug(data_dicts)\n",
    "\n",
    "\n",
    "dataset = CovidDataset(volumes=data_dicts1, hrct_transform=get_raw_transforms(), cbct_transform=get_raw_transforms())\n",
    "dataloader = DataLoader(dataset, batch_size=1, num_workers=2)\n"
   ],
   "id": "2d920cdef541099a",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T11:13:02.994650Z",
     "start_time": "2024-07-16T11:13:02.989726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a radiopaedia dataset\n",
    "radiopaedia_dataset = CovidDataset(volumes=data_dicts, hrct_transform=get_raw_transforms(), cbct_transform=get_raw_transforms())\n",
    "radiopaedia_loader = DataLoader(radiopaedia_dataset, batch_size=1, num_workers=2)"
   ],
   "id": "4f3fcf3867069466",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T09:57:12.804676Z",
     "start_time": "2024-07-15T09:56:47.714904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i, data in enumerate(dataloader):\n",
    "    print(data[\"img\"].min(), data[\"img\"].max())"
   ],
   "id": "b03633afdb22c402",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metatensor(-2048.) metatensor(5351.)\n",
      "metatensor(-2048.) metatensor(1754.)\n",
      "metatensor(-2048.) metatensor(1831.)\n",
      "metatensor(-2828.) metatensor(16608.)\n",
      "metatensor(-2048.) metatensor(1815.)\n",
      "metatensor(-2048.) metatensor(1916.)\n",
      "metatensor(-2048.) metatensor(1704.)\n",
      "metatensor(-4535.) metatensor(21549.)\n",
      "metatensor(-2048.) metatensor(1734.)\n",
      "metatensor(-2048.) metatensor(1623.)\n",
      "metatensor(-2048.) metatensor(1732.)\n",
      "metatensor(-2048.) metatensor(4740.)\n",
      "metatensor(-2048.) metatensor(1722.)\n",
      "metatensor(-2048.) metatensor(1703.)\n",
      "metatensor(-2048.) metatensor(1766.)\n",
      "metatensor(-2048.) metatensor(1788.)\n",
      "metatensor(-2048.) metatensor(1692.)\n",
      "metatensor(-2048.) metatensor(1901.)\n",
      "metatensor(-2048.) metatensor(1863.)\n",
      "metatensor(-2048.) metatensor(1619.)\n",
      "metatensor(-2048.) metatensor(2545.)\n",
      "metatensor(-2048.) metatensor(1798.)\n",
      "metatensor(-2048.) metatensor(2056.)\n",
      "metatensor(-2048.) metatensor(1782.)\n",
      "metatensor(-2048.) metatensor(1685.)\n",
      "metatensor(-2048.) metatensor(1770.)\n",
      "metatensor(-2048.) metatensor(1592.)\n",
      "metatensor(-2048.) metatensor(1925.)\n",
      "metatensor(-2048.) metatensor(1663.)\n",
      "metatensor(-2048.) metatensor(5113.)\n",
      "metatensor(-2048.) metatensor(1733.)\n",
      "metatensor(-2048.) metatensor(1829.)\n",
      "metatensor(-2048.) metatensor(1742.)\n",
      "metatensor(-2048.) metatensor(1911.)\n",
      "metatensor(-2048.) metatensor(1720.)\n",
      "metatensor(-2048.) metatensor(1669.)\n",
      "metatensor(-2048.) metatensor(1883.)\n",
      "metatensor(-2048.) metatensor(1712.)\n",
      "metatensor(-2048.) metatensor(1821.)\n",
      "metatensor(-2048.) metatensor(1771.)\n",
      "metatensor(-2048.) metatensor(1824.)\n",
      "metatensor(-2048.) metatensor(1739.)\n",
      "metatensor(-2048.) metatensor(1731.)\n",
      "metatensor(-2053.) metatensor(5758.)\n",
      "metatensor(-2048.) metatensor(1691.)\n",
      "metatensor(-2048.) metatensor(1743.)\n",
      "metatensor(-2048.) metatensor(1731.)\n",
      "metatensor(-2048.) metatensor(1722.)\n",
      "metatensor(-2048.) metatensor(1790.)\n",
      "metatensor(-2048.) metatensor(1684.)\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T08:24:00.625031Z",
     "start_time": "2024-07-05T08:24:00.566084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def t():\n",
    "    return monai.transforms.Compose(\n",
    "        [\n",
    "            # monai.transforms.LoadImaged(keys=('img', 'mask'), image_only=True, ensure_channel_first=True),\n",
    "            monai.transforms.Orientationd(keys=('img', 'mask'), axcodes=\"PLI\"),\n",
    "            monai.transforms.ScaleIntensityRanged(keys=('img',), a_min=LOWER_BOUND_WINDOW_HRCT,\n",
    "                                            a_max=UPPER_BOUND_WINDOW_HRCT, b_min=0.0, b_max=1.0, clip=True),\n",
    "            monai.transforms.ToTensord(keys=(\"img\", \"mask\")),\n",
    "        ]\n",
    "    )\n",
    "sample_data = {\n",
    "    'img': np.random.randint(-2000, 2000, (2, 128, 128, 128)),  # Example volume\n",
    "    'mask': np.random.randint(0, 2, (2, 128, 128, 128))         # Example mask\n",
    "}\n",
    "\n",
    "transforms_pipeline = t()\n",
    "transformed_data = transforms_pipeline(sample_data)\n",
    "\n",
    "# Print some statistics of the normalized volume to verify\n",
    "print(f\"Min value (img): {transformed_data['img'].min()}\")\n",
    "print(f\"Max value (img): {transformed_data['img'].max()}\")\n",
    "print(f\"Mean value (img): {transformed_data['img'].mean()}\")"
   ],
   "id": "77b155b09381829f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min value (img): 0.0\n",
      "Max value (img): 1.0\n",
      "Mean value (img): 0.6622612476348877\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T10:17:16.773191Z",
     "start_time": "2024-07-15T10:17:16.746970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import nibabel and load an image from data_paths and explore the min and max value of each image\n",
    "import nibabel as nib\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "min = [100000,1000000,100000]\n",
    "for i in range(len(data_dicts)):\n",
    "    f = nib.load(data_dicts[i][\"img\"])\n",
    "    if min[0] > abs(f.header[\"srow_x\"][0]):\n",
    "        min[0] = abs(f.header[\"srow_x\"][0])\n",
    "    if min[1] > abs(f.header[\"srow_y\"][1]):\n",
    "        min[1] = abs(f.header[\"srow_y\"][1])\n",
    "    if min[2] > abs(f.header[\"srow_z\"][2]):\n",
    "        min[2] = abs(f.header[\"srow_z\"][2])\n",
    "print(min) "
   ],
   "id": "34e3074c79b4fcb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.671\n",
      "0.595\n",
      "0.708\n",
      "0.647\n",
      "0.782\n",
      "0.801\n",
      "0.782\n",
      "0.705\n",
      "0.668\n",
      "0.751\n",
      "0.782\n",
      "0.782\n",
      "0.782\n",
      "0.782\n",
      "0.781\n",
      "0.686\n",
      "0.647\n",
      "0.698\n",
      "0.724\n",
      "0.629\n",
      "0.705\n",
      "0.671\n",
      "0.598\n",
      "0.65\n",
      "0.782\n",
      "0.694\n",
      "0.698\n",
      "0.582\n",
      "0.812\n",
      "0.736\n",
      "0.782\n",
      "0.782\n",
      "0.677\n",
      "0.708\n",
      "0.801\n",
      "0.668\n",
      "0.637\n",
      "0.702\n",
      "0.781\n",
      "0.705\n",
      "0.753\n",
      "0.662\n",
      "0.677\n",
      "1.152\n",
      "0.631\n",
      "0.923\n",
      "0.729\n",
      "0.74\n",
      "0.613\n",
      "0.846\n",
      "[0.582, 0.582, 8.0]\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "662cdf21336c85a7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T11:10:38.325411Z",
     "start_time": "2024-07-16T11:10:10.763492Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i, data in enumerate(radiopaedia_loader):\n",
    "    print(f'{radiopaedia_dataset.volumes[i][\"img\"].split(\"/\")[-1]}_{data[\"img_meta_dict\"][\"pixdim\"][0][1:4]}')\n",
    "    print(f'{data[\"img\"].shape}')"
   ],
   "id": "44d23444bf86a1f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coronacases_001.nii.gz_tensor([0.8105, 0.8105, 1.0000])\n",
      "torch.Size([1, 1, 512, 512, 301])\n",
      "coronacases_002.nii.gz_tensor([0.6836, 0.6836, 1.5000])\n",
      "torch.Size([1, 1, 512, 512, 200])\n",
      "coronacases_003.nii.gz_tensor([0.7363, 0.7363, 1.5000])\n",
      "torch.Size([1, 1, 512, 512, 200])\n",
      "coronacases_004.nii.gz_tensor([0.6836, 0.6836, 1.0000])\n",
      "torch.Size([1, 1, 512, 512, 270])\n",
      "coronacases_005.nii.gz_tensor([0.6836, 0.6836, 1.0000])\n",
      "torch.Size([1, 1, 512, 512, 290])\n",
      "coronacases_006.nii.gz_tensor([0.7598, 0.7598, 1.5000])\n",
      "torch.Size([1, 1, 512, 512, 213])\n",
      "coronacases_007.nii.gz_tensor([0.7129, 0.7129, 1.0000])\n",
      "torch.Size([1, 1, 512, 512, 249])\n",
      "coronacases_008.nii.gz_tensor([0.7246, 0.7246, 1.0000])\n",
      "torch.Size([1, 1, 512, 512, 301])\n",
      "coronacases_009.nii.gz_tensor([0.6836, 0.6836, 1.0000])\n",
      "torch.Size([1, 1, 512, 512, 256])\n",
      "coronacases_010.nii.gz_tensor([0.6836, 0.6836, 1.0000])\n",
      "torch.Size([1, 1, 512, 512, 301])\n",
      "radiopaedia_10_85902_1.nii.gz_tensor([0.6836, 0.6836, 6.0000])\n",
      "torch.Size([1, 1, 630, 630, 39])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(radiopaedia_loader):\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mradiopaedia_dataset\u001B[38;5;241m.\u001B[39mvolumes[i][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimg\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/\u001B[39m\u001B[38;5;124m\"\u001B[39m)[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdata[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimg_meta_dict\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpixdim\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;241m0\u001B[39m][\u001B[38;5;241m1\u001B[39m:\u001B[38;5;241m4\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      3\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdata[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimg\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mshape\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/mi-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    630\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 631\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_data()\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    635\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/miniconda3/envs/mi-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1329\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_data(data)\n\u001B[1;32m   1328\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shutdown \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m-> 1329\u001B[0m idx, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_data()\n\u001B[1;32m   1330\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1331\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable:\n\u001B[1;32m   1332\u001B[0m     \u001B[38;5;66;03m# Check for _IterableDatasetStopIteration\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/mi-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1295\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._get_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1291\u001B[0m     \u001B[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001B[39;00m\n\u001B[1;32m   1292\u001B[0m     \u001B[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001B[39;00m\n\u001B[1;32m   1293\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1294\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m-> 1295\u001B[0m         success, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_try_get_data()\n\u001B[1;32m   1296\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m success:\n\u001B[1;32m   1297\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[0;32m~/miniconda3/envs/mi-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1133\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m   1120\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_try_get_data\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout\u001B[38;5;241m=\u001B[39m_utils\u001B[38;5;241m.\u001B[39mMP_STATUS_CHECK_INTERVAL):\n\u001B[1;32m   1121\u001B[0m     \u001B[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001B[39;00m\n\u001B[1;32m   1122\u001B[0m     \u001B[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1130\u001B[0m     \u001B[38;5;66;03m# Returns a 2-tuple:\u001B[39;00m\n\u001B[1;32m   1131\u001B[0m     \u001B[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1133\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_queue\u001B[38;5;241m.\u001B[39mget(timeout\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[1;32m   1134\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mTrue\u001B[39;00m, data)\n\u001B[1;32m   1135\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1136\u001B[0m         \u001B[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001B[39;00m\n\u001B[1;32m   1137\u001B[0m         \u001B[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001B[39;00m\n\u001B[1;32m   1138\u001B[0m         \u001B[38;5;66;03m# worker failures.\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/mi-env/lib/python3.11/multiprocessing/queues.py:113\u001B[0m, in \u001B[0;36mQueue.get\u001B[0;34m(self, block, timeout)\u001B[0m\n\u001B[1;32m    111\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m block:\n\u001B[1;32m    112\u001B[0m     timeout \u001B[38;5;241m=\u001B[39m deadline \u001B[38;5;241m-\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic()\n\u001B[0;32m--> 113\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_poll(timeout):\n\u001B[1;32m    114\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m Empty\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_poll():\n",
      "File \u001B[0;32m~/miniconda3/envs/mi-env/lib/python3.11/multiprocessing/connection.py:257\u001B[0m, in \u001B[0;36m_ConnectionBase.poll\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    255\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_closed()\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_readable()\n\u001B[0;32m--> 257\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_poll(timeout)\n",
      "File \u001B[0;32m~/miniconda3/envs/mi-env/lib/python3.11/multiprocessing/connection.py:440\u001B[0m, in \u001B[0;36mConnection._poll\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    439\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_poll\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout):\n\u001B[0;32m--> 440\u001B[0m     r \u001B[38;5;241m=\u001B[39m wait([\u001B[38;5;28mself\u001B[39m], timeout)\n\u001B[1;32m    441\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mbool\u001B[39m(r)\n",
      "File \u001B[0;32m~/miniconda3/envs/mi-env/lib/python3.11/multiprocessing/connection.py:948\u001B[0m, in \u001B[0;36mwait\u001B[0;34m(object_list, timeout)\u001B[0m\n\u001B[1;32m    945\u001B[0m     deadline \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic() \u001B[38;5;241m+\u001B[39m timeout\n\u001B[1;32m    947\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 948\u001B[0m     ready \u001B[38;5;241m=\u001B[39m selector\u001B[38;5;241m.\u001B[39mselect(timeout)\n\u001B[1;32m    949\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ready:\n\u001B[1;32m    950\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [key\u001B[38;5;241m.\u001B[39mfileobj \u001B[38;5;28;01mfor\u001B[39;00m (key, events) \u001B[38;5;129;01min\u001B[39;00m ready]\n",
      "File \u001B[0;32m~/miniconda3/envs/mi-env/lib/python3.11/selectors.py:415\u001B[0m, in \u001B[0;36m_PollLikeSelector.select\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    413\u001B[0m ready \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    414\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 415\u001B[0m     fd_event_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_selector\u001B[38;5;241m.\u001B[39mpoll(timeout)\n\u001B[1;32m    416\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mInterruptedError\u001B[39;00m:\n\u001B[1;32m    417\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ready\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T11:10:50.167927Z",
     "start_time": "2024-07-15T11:10:37.145369Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i, data in enumerate(dataloader):\n",
    "    print(data[\"img_meta_dict\"][\"pixdim\"][0][1:4])"
   ],
   "id": "a4adeb71345eec0b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6710, 0.6710, 8.0000])\n",
      "tensor([0.5950, 0.5950, 8.0000])\n",
      "tensor([0.7080, 0.7080, 8.0000])\n",
      "tensor([0.6470, 0.6470, 8.0000])\n",
      "tensor([0.7820, 0.7820, 8.0000])\n",
      "tensor([0.8010, 0.8010, 8.0000])\n",
      "tensor([0.7820, 0.7820, 8.0000])\n",
      "tensor([0.7050, 0.7050, 8.0000])\n",
      "tensor([0.6680, 0.6680, 8.0000])\n",
      "tensor([0.7510, 0.7510, 8.0000])\n",
      "tensor([0.7820, 0.7820, 8.0000])\n",
      "tensor([0.7820, 0.7820, 8.0000])\n",
      "tensor([0.7820, 0.7820, 8.0000])\n",
      "tensor([0.7820, 0.7820, 8.0000])\n",
      "tensor([0.7810, 0.7810, 8.0000])\n",
      "tensor([0.6860, 0.6860, 8.0000])\n",
      "tensor([0.6470, 0.6470, 8.0000])\n",
      "tensor([0.6980, 0.6980, 8.0000])\n",
      "tensor([0.7240, 0.7240, 8.0000])\n",
      "tensor([0.6290, 0.6290, 8.0000])\n",
      "tensor([0.7050, 0.7050, 8.0000])\n",
      "tensor([0.6710, 0.6710, 8.0000])\n",
      "tensor([0.5980, 0.5980, 8.0000])\n",
      "tensor([0.6500, 0.6500, 8.0000])\n",
      "tensor([0.7820, 0.7820, 8.0000])\n",
      "tensor([0.6940, 0.6940, 8.0000])\n",
      "tensor([0.6980, 0.6980, 8.0000])\n",
      "tensor([0.5820, 0.5820, 8.0000])\n",
      "tensor([0.8120, 0.8120, 8.0000])\n",
      "tensor([0.7360, 0.7360, 8.0000])\n",
      "tensor([0.7820, 0.7820, 8.0000])\n",
      "tensor([0.7820, 0.7820, 8.0000])\n",
      "tensor([0.6770, 0.6770, 8.0000])\n",
      "tensor([0.7080, 0.7080, 8.0000])\n",
      "tensor([0.8010, 0.8010, 8.0000])\n",
      "tensor([0.6680, 0.6680, 8.0000])\n",
      "tensor([0.6370, 0.6370, 8.0000])\n",
      "tensor([0.7020, 0.7020, 8.0000])\n",
      "tensor([0.7810, 0.7810, 8.0000])\n",
      "tensor([0.7050, 0.7050, 8.0000])\n",
      "tensor([0.7530, 0.7530, 8.0000])\n",
      "tensor([0.6620, 0.6620, 8.0000])\n",
      "tensor([0.6770, 0.6770, 8.0000])\n",
      "tensor([1.1520, 1.1520, 8.0000])\n",
      "tensor([0.6310, 0.6310, 8.0000])\n",
      "tensor([0.9230, 0.9230, 8.0000])\n",
      "tensor([0.7290, 0.7290, 8.0000])\n",
      "tensor([0.7400, 0.7400, 8.0000])\n",
      "tensor([0.6130, 0.6130, 8.0000])\n",
      "tensor([0.8460, 0.8460, 8.0000])\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T11:13:58.541414Z",
     "start_time": "2024-07-16T11:13:23.505443Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Now we are going to take the mean values from the data[\"img_meta_dict\"][\"pixdim\"][0][1:4] from each dimension 1, 2, 3 for \n",
    "# both datasets\n",
    "values = []\n",
    "for i, data in enumerate(dataloader):\n",
    "    values.append(list(data[\"img_meta_dict\"][\"pixdim\"][0][1:4]))\n",
    "\n",
    "for i, data in enumerate(radiopaedia_loader):\n",
    "    values.append(list(data[\"img_meta_dict\"][\"pixdim\"][0][1:4]))\n"
   ],
   "id": "1ceb239ed8e1bf57",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T11:13:58.571200Z",
     "start_time": "2024-07-16T11:13:58.542584Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in values:\n",
    "    print(i)\n",
    "# print mean values for each dimension\n",
    "print(np.mean(values, axis=0))\n",
    "\n",
    "    "
   ],
   "id": "742b61e905c6acfa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(0.6710), tensor(0.6710), tensor(8.)]\n",
      "[tensor(0.5950), tensor(0.5950), tensor(8.)]\n",
      "[tensor(0.7080), tensor(0.7080), tensor(8.)]\n",
      "[tensor(0.6470), tensor(0.6470), tensor(8.)]\n",
      "[tensor(0.7820), tensor(0.7820), tensor(8.)]\n",
      "[tensor(0.8010), tensor(0.8010), tensor(8.)]\n",
      "[tensor(0.7820), tensor(0.7820), tensor(8.)]\n",
      "[tensor(0.7050), tensor(0.7050), tensor(8.)]\n",
      "[tensor(0.6680), tensor(0.6680), tensor(8.)]\n",
      "[tensor(0.7510), tensor(0.7510), tensor(8.)]\n",
      "[tensor(0.7820), tensor(0.7820), tensor(8.)]\n",
      "[tensor(0.7820), tensor(0.7820), tensor(8.)]\n",
      "[tensor(0.7820), tensor(0.7820), tensor(8.)]\n",
      "[tensor(0.7820), tensor(0.7820), tensor(8.)]\n",
      "[tensor(0.7810), tensor(0.7810), tensor(8.)]\n",
      "[tensor(0.6860), tensor(0.6860), tensor(8.)]\n",
      "[tensor(0.6470), tensor(0.6470), tensor(8.)]\n",
      "[tensor(0.6980), tensor(0.6980), tensor(8.)]\n",
      "[tensor(0.7240), tensor(0.7240), tensor(8.)]\n",
      "[tensor(0.6290), tensor(0.6290), tensor(8.)]\n",
      "[tensor(0.7050), tensor(0.7050), tensor(8.)]\n",
      "[tensor(0.6710), tensor(0.6710), tensor(8.)]\n",
      "[tensor(0.5980), tensor(0.5980), tensor(8.)]\n",
      "[tensor(0.6500), tensor(0.6500), tensor(8.)]\n",
      "[tensor(0.7820), tensor(0.7820), tensor(8.)]\n",
      "[tensor(0.6940), tensor(0.6940), tensor(8.)]\n",
      "[tensor(0.6980), tensor(0.6980), tensor(8.)]\n",
      "[tensor(0.5820), tensor(0.5820), tensor(8.)]\n",
      "[tensor(0.8120), tensor(0.8120), tensor(8.)]\n",
      "[tensor(0.7360), tensor(0.7360), tensor(8.)]\n",
      "[tensor(0.7820), tensor(0.7820), tensor(8.)]\n",
      "[tensor(0.7820), tensor(0.7820), tensor(8.)]\n",
      "[tensor(0.6770), tensor(0.6770), tensor(8.)]\n",
      "[tensor(0.7080), tensor(0.7080), tensor(8.)]\n",
      "[tensor(0.8010), tensor(0.8010), tensor(8.)]\n",
      "[tensor(0.6680), tensor(0.6680), tensor(8.)]\n",
      "[tensor(0.6370), tensor(0.6370), tensor(8.)]\n",
      "[tensor(0.7020), tensor(0.7020), tensor(8.)]\n",
      "[tensor(0.7810), tensor(0.7810), tensor(8.)]\n",
      "[tensor(0.7050), tensor(0.7050), tensor(8.)]\n",
      "[tensor(0.7530), tensor(0.7530), tensor(8.)]\n",
      "[tensor(0.6620), tensor(0.6620), tensor(8.)]\n",
      "[tensor(0.6770), tensor(0.6770), tensor(8.)]\n",
      "[tensor(1.1520), tensor(1.1520), tensor(8.)]\n",
      "[tensor(0.6310), tensor(0.6310), tensor(8.)]\n",
      "[tensor(0.9230), tensor(0.9230), tensor(8.)]\n",
      "[tensor(0.7290), tensor(0.7290), tensor(8.)]\n",
      "[tensor(0.7400), tensor(0.7400), tensor(8.)]\n",
      "[tensor(0.6130), tensor(0.6130), tensor(8.)]\n",
      "[tensor(0.8460), tensor(0.8460), tensor(8.)]\n",
      "[tensor(0.8105), tensor(0.8105), tensor(1.)]\n",
      "[tensor(0.6836), tensor(0.6836), tensor(1.5000)]\n",
      "[tensor(0.7363), tensor(0.7363), tensor(1.5000)]\n",
      "[tensor(0.6836), tensor(0.6836), tensor(1.)]\n",
      "[tensor(0.6836), tensor(0.6836), tensor(1.)]\n",
      "[tensor(0.7598), tensor(0.7598), tensor(1.5000)]\n",
      "[tensor(0.7129), tensor(0.7129), tensor(1.)]\n",
      "[tensor(0.7246), tensor(0.7246), tensor(1.)]\n",
      "[tensor(0.6836), tensor(0.6836), tensor(1.)]\n",
      "[tensor(0.6836), tensor(0.6836), tensor(1.)]\n",
      "[tensor(0.6836), tensor(0.6836), tensor(6.)]\n",
      "[tensor(0.6836), tensor(0.6836), tensor(1.)]\n",
      "[tensor(0.6836), tensor(0.6836), tensor(2.)]\n",
      "[tensor(0.6836), tensor(0.6836), tensor(6.)]\n",
      "[tensor(0.6836), tensor(0.6836), tensor(6.)]\n",
      "[tensor(0.6836), tensor(0.6836), tensor(6.)]\n",
      "[tensor(0.6836), tensor(0.6836), tensor(6.)]\n",
      "[tensor(0.6836), tensor(0.6836), tensor(4.)]\n",
      "[tensor(0.6836), tensor(0.6836), tensor(6.)]\n",
      "[tensor(0.6836), tensor(0.6836), tensor(6.)]\n",
      "[0.7185435 0.7185435 6.5785713]\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 512, 512, 39])\n",
      "torch.Size([1, 1, 512, 512, 33])\n",
      "torch.Size([1, 1, 512, 512, 41])\n",
      "torch.Size([1, 1, 512, 512, 41])\n",
      "torch.Size([1, 1, 512, 512, 46])\n",
      "torch.Size([1, 1, 512, 512, 39])\n",
      "torch.Size([1, 1, 512, 512, 41])\n",
      "torch.Size([1, 1, 512, 512, 42])\n",
      "torch.Size([1, 1, 512, 512, 38])\n",
      "torch.Size([1, 1, 512, 512, 43])\n",
      "torch.Size([1, 1, 512, 512, 41])\n",
      "torch.Size([1, 1, 512, 512, 37])\n",
      "torch.Size([1, 1, 512, 512, 39])\n",
      "torch.Size([1, 1, 512, 512, 45])\n",
      "torch.Size([1, 1, 512, 512, 45])\n",
      "torch.Size([1, 1, 512, 512, 38])\n",
      "torch.Size([1, 1, 512, 512, 33])\n",
      "torch.Size([1, 1, 512, 512, 48])\n",
      "torch.Size([1, 1, 512, 512, 43])\n",
      "torch.Size([1, 1, 512, 512, 41])\n",
      "torch.Size([1, 1, 512, 512, 41])\n",
      "torch.Size([1, 1, 512, 512, 41])\n",
      "torch.Size([1, 1, 512, 512, 41])\n",
      "torch.Size([1, 1, 512, 512, 41])\n",
      "torch.Size([1, 1, 512, 512, 37])\n",
      "torch.Size([1, 1, 512, 512, 42])\n",
      "torch.Size([1, 1, 512, 512, 43])\n",
      "torch.Size([1, 1, 512, 512, 43])\n",
      "torch.Size([1, 1, 512, 512, 39])\n",
      "torch.Size([1, 1, 512, 512, 40])\n",
      "torch.Size([1, 1, 512, 512, 46])\n",
      "torch.Size([1, 1, 512, 512, 41])\n",
      "torch.Size([1, 1, 512, 512, 42])\n",
      "torch.Size([1, 1, 512, 512, 38])\n",
      "torch.Size([1, 1, 512, 512, 40])\n",
      "torch.Size([1, 1, 512, 512, 38])\n",
      "torch.Size([1, 1, 512, 512, 38])\n",
      "torch.Size([1, 1, 512, 512, 41])\n",
      "torch.Size([1, 1, 512, 512, 45])\n",
      "torch.Size([1, 1, 512, 512, 43])\n",
      "torch.Size([1, 1, 512, 512, 38])\n",
      "torch.Size([1, 1, 512, 512, 41])\n",
      "torch.Size([1, 1, 512, 512, 38])\n",
      "torch.Size([1, 1, 512, 512, 34])\n",
      "torch.Size([1, 1, 512, 512, 47])\n",
      "torch.Size([1, 1, 512, 512, 38])\n",
      "torch.Size([1, 1, 512, 512, 41])\n",
      "torch.Size([1, 1, 512, 512, 45])\n",
      "torch.Size([1, 1, 512, 512, 41])\n",
      "torch.Size([1, 1, 512, 512, 53])\n"
     ]
    }
   ],
   "execution_count": 25,
   "source": [
    "# print the resolution of the images\n",
    "for i, data in enumerate(dataloader):\n",
    "    print(data[\"img\"].shape)\n",
    "# Now we are going to take the mean values for "
   ],
   "id": "7a8d5204fabcd7cf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T11:08:27.164389Z",
     "start_time": "2024-07-15T11:08:27.161908Z"
    }
   },
   "cell_type": "code",
   "source": "len(data_dicts)",
   "id": "3b39c7b008171f1a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
