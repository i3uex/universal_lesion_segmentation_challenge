{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-11T16:08:15.839920Z",
     "start_time": "2024-07-11T16:08:11.766703Z"
    }
   },
   "source": [
    "import logging\n",
    "from monai.data import DataLoader\n",
    "import monai\n",
    "from config.constants import (COVID_CASES_PATH, INFECTION_MASKS_PATH)\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from monai.visualize import plot_2d_or_3d_image, matshow3d, blend_images\n",
    "from pathlib import Path\n",
    "from utils.helpers import load_images_from_path"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-11 18:08:14.308479: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-11 18:08:15.149198: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T16:09:24.319747Z",
     "start_time": "2024-07-11T16:09:24.305028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SPATIAL_SIZE = (32, 32, 32)\n",
    "NUM_RAND_PATCHES = 4\n",
    "LEVEL = -650\n",
    "WIDTH = 1500\n",
    "LOWER_BOUND_WINDOW_HRCT = LEVEL - (WIDTH // 2) \n",
    "UPPER_BOUND_WINDOW_HRCT = LEVEL + (WIDTH // 2)\n",
    "LOWER_BOUND_WINDOW_CBCT = 0\n",
    "UPPER_BOUND_WINDOW_CBCT = 255\n",
    "SEED = 33\n",
    "\n",
    "\n",
    "print(LOWER_BOUND_WINDOW_HRCT)\n",
    "print(UPPER_BOUND_WINDOW_HRCT)\n",
    "def get_hrct_transforms():\n",
    "    return monai.transforms.Compose(\n",
    "        [\n",
    "            monai.transforms.LoadImaged(keys=('img', 'mask'), image_only=True, ensure_channel_first=True),\n",
    "            monai.transforms.Orientationd(keys=('img', 'mask'), axcodes=\"PLI\"),\n",
    "            monai.transforms.ThresholdIntensityd(keys=(\"img\",), threshold=LOWER_BOUND_WINDOW_HRCT, above=False, cval=LOWER_BOUND_WINDOW_HRCT),\n",
    "            monai.transforms.ThresholdIntensityd(keys=(\"img\",), threshold=UPPER_BOUND_WINDOW_HRCT, above=True, cval=UPPER_BOUND_WINDOW_HRCT),\n",
    "            monai.transforms.ScaleIntensityRanged(keys=('img',), a_min=LOWER_BOUND_WINDOW_HRCT,\n",
    "                                                  a_max=UPPER_BOUND_WINDOW_HRCT, b_min=0.0, b_max=1.0, clip=True, allow_missing_keys=True),\n",
    "            monai.transforms.RandCropByPosNegLabeld(keys=('img', 'mask'), label_key=\"mask\",\n",
    "                                                    spatial_size=SPATIAL_SIZE, pos=1, neg=1,\n",
    "                                                    num_samples=NUM_RAND_PATCHES, allow_smaller=True),\n",
    "            monai.transforms.ToTensord(keys=(\"img\", \"mask\")),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def get_cbct_transforms():\n",
    "    return monai.transforms.Compose(\n",
    "        [\n",
    "            monai.transforms.LoadImaged(keys=('img', 'mask'), image_only=True, ensure_channel_first=True),\n",
    "            monai.transforms.Orientationd(keys=('img', 'mask'), axcodes=\"ALI\"),\n",
    "            monai.transforms.RandCropByPosNegLabeld(keys=('img', 'mask'), label_key=\"mask\",\n",
    "                                                    spatial_size=SPATIAL_SIZE, pos=1, neg=1,\n",
    "                                                    num_samples=NUM_RAND_PATCHES, allow_smaller=True),\n",
    "            monai.transforms.ScaleIntensityd(keys='img', minv=0.0, maxv=1.0),\n",
    "            monai.transforms.ToTensord(keys=(\"img\", \"mask\")),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def get_val_hrct_transforms():\n",
    "    return monai.transforms.Compose(\n",
    "        [\n",
    "            monai.transforms.LoadImaged(keys=('img', 'mask'), image_only=True, ensure_channel_first=True),\n",
    "            monai.transforms.Orientationd(keys=('img', 'mask'), axcodes=\"PLI\"),\n",
    "            monai.transforms.ThresholdIntensityd(keys=(\"img\",), threshold=LOWER_BOUND_WINDOW_HRCT, above=True, cval=LOWER_BOUND_WINDOW_HRCT),\n",
    "            monai.transforms.ThresholdIntensityd(keys=(\"img\",), threshold=UPPER_BOUND_WINDOW_HRCT, above=False, cval=UPPER_BOUND_WINDOW_HRCT),\n",
    "            monai.transforms.ScaleIntensityd(keys='img', minv=0.0, maxv=1.0),\n",
    "            monai.transforms.ToTensord(keys=(\"img\", \"mask\")),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def get_val_cbct_transforms():\n",
    "    print(\"asdfas\")\n",
    "    return monai.transforms.Compose(\n",
    "        [\n",
    "            monai.transforms.LoadImaged(keys=('img', 'mask'), image_only=True, ensure_channel_first=True),\n",
    "            monai.transforms.Orientationd(keys=('img', 'mask'), axcodes=\"ALI\"),\n",
    "            monai.transforms.ScaleIntensityd(keys='img', minv=0.0, maxv=1.0),\n",
    "            monai.transforms.ToTensord(keys=(\"img\", \"mask\")),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def get_raw_transforms():\n",
    "    return monai.transforms.Compose(\n",
    "        [\n",
    "            monai.transforms.LoadImaged(keys=('img', 'mask'), image_only=False, ensure_channel_first=True),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def load_radiopaedia_from_path(path: str) -> list[str]:\n",
    "    return sorted([str(f) for f in Path(path).iterdir() if f.suffix == '.gz' and f.is_file() and 'radiopaedia' in f.stem])\n",
    "\n",
    "class CovidDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, volumes, hrct_transform=None, cbct_transform=None):\n",
    "        self.volumes = volumes\n",
    "        self.hrct_transform = hrct_transform\n",
    "        self.cbct_transform = cbct_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.volumes)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        volume = self.volumes[index]\n",
    "\n",
    "        if \"coronacases\" in volume[\"img\"]:\n",
    "            return self.hrct_transform(volume)\n",
    "        else:\n",
    "            return self.cbct_transform(volume)\n",
    "        \n",
    "# Load images and masks\n",
    "logging.info(f\"Loading images from {COVID_CASES_PATH}\")\n",
    "images = load_radiopaedia_from_path(\"../\" + COVID_CASES_PATH)\n",
    "labels = load_radiopaedia_from_path(\"../\" + INFECTION_MASKS_PATH)\n",
    "\n",
    "\n",
    "# Convert images and masks to a list of dictionaries with keys \"img\" and \"mask\"\n",
    "data_dicts = np.array([{\"img\": img, \"mask\": mask} for img, mask in zip(images, labels)])\n",
    "logging.debug(data_dicts)\n",
    "\n",
    "shuffler = np.random.RandomState(SEED)\n",
    "shuffler.shuffle(data_dicts)\n",
    "data_dicts = list(data_dicts)\n",
    "\n"
   ],
   "id": "99b8b39e7c9dc268",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1400\n",
      "100\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T16:09:26.402350Z",
     "start_time": "2024-07-11T16:09:26.396306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create a radiopaedia dataset\n",
    "radiopaedia_dataset = CovidDataset(volumes=data_dicts, hrct_transform=get_raw_transforms(), cbct_transform=get_raw_transforms())\n",
    "radiopaedia_loader = DataLoader(radiopaedia_dataset, batch_size=1, num_workers=2)"
   ],
   "id": "4f3fcf3867069466",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T16:08:28.869007Z",
     "start_time": "2024-07-11T16:08:21.653489Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i, data in enumerate(radiopaedia_loader):\n",
    "    print(data[\"img\"].min(), data[\"img\"].max())"
   ],
   "id": "b03633afdb22c402",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metatensor(-1021.) metatensor(1845.)\n",
      "metatensor(-1021.) metatensor(2020.)\n",
      "metatensor(-1023.) metatensor(2217.)\n",
      "metatensor(-1021.) metatensor(1920.)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(radiopaedia_loader):\n\u001B[1;32m      2\u001B[0m     \u001B[38;5;28mprint\u001B[39m(data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimg\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mmin(), data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimg\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mmax())\n",
      "File \u001B[0;32m~/miniconda3/envs/mi-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    630\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 631\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_data()\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    635\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/miniconda3/envs/mi-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1329\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1326\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_process_data(data)\n\u001B[1;32m   1328\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shutdown \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m-> 1329\u001B[0m idx, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_data()\n\u001B[1;32m   1330\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m   1331\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable:\n\u001B[1;32m   1332\u001B[0m     \u001B[38;5;66;03m# Check for _IterableDatasetStopIteration\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/mi-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1295\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._get_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1291\u001B[0m     \u001B[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001B[39;00m\n\u001B[1;32m   1292\u001B[0m     \u001B[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001B[39;00m\n\u001B[1;32m   1293\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1294\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m-> 1295\u001B[0m         success, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_try_get_data()\n\u001B[1;32m   1296\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m success:\n\u001B[1;32m   1297\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[0;32m~/miniconda3/envs/mi-env/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1133\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m   1120\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_try_get_data\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout\u001B[38;5;241m=\u001B[39m_utils\u001B[38;5;241m.\u001B[39mMP_STATUS_CHECK_INTERVAL):\n\u001B[1;32m   1121\u001B[0m     \u001B[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001B[39;00m\n\u001B[1;32m   1122\u001B[0m     \u001B[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1130\u001B[0m     \u001B[38;5;66;03m# Returns a 2-tuple:\u001B[39;00m\n\u001B[1;32m   1131\u001B[0m     \u001B[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001B[39;00m\n\u001B[1;32m   1132\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1133\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data_queue\u001B[38;5;241m.\u001B[39mget(timeout\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[1;32m   1134\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[38;5;28;01mTrue\u001B[39;00m, data)\n\u001B[1;32m   1135\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1136\u001B[0m         \u001B[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001B[39;00m\n\u001B[1;32m   1137\u001B[0m         \u001B[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001B[39;00m\n\u001B[1;32m   1138\u001B[0m         \u001B[38;5;66;03m# worker failures.\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/mi-env/lib/python3.11/multiprocessing/queues.py:113\u001B[0m, in \u001B[0;36mQueue.get\u001B[0;34m(self, block, timeout)\u001B[0m\n\u001B[1;32m    111\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m block:\n\u001B[1;32m    112\u001B[0m     timeout \u001B[38;5;241m=\u001B[39m deadline \u001B[38;5;241m-\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic()\n\u001B[0;32m--> 113\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_poll(timeout):\n\u001B[1;32m    114\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m Empty\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_poll():\n",
      "File \u001B[0;32m~/miniconda3/envs/mi-env/lib/python3.11/multiprocessing/connection.py:257\u001B[0m, in \u001B[0;36m_ConnectionBase.poll\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    255\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_closed()\n\u001B[1;32m    256\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_readable()\n\u001B[0;32m--> 257\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_poll(timeout)\n",
      "File \u001B[0;32m~/miniconda3/envs/mi-env/lib/python3.11/multiprocessing/connection.py:440\u001B[0m, in \u001B[0;36mConnection._poll\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    439\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_poll\u001B[39m(\u001B[38;5;28mself\u001B[39m, timeout):\n\u001B[0;32m--> 440\u001B[0m     r \u001B[38;5;241m=\u001B[39m wait([\u001B[38;5;28mself\u001B[39m], timeout)\n\u001B[1;32m    441\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mbool\u001B[39m(r)\n",
      "File \u001B[0;32m~/miniconda3/envs/mi-env/lib/python3.11/multiprocessing/connection.py:948\u001B[0m, in \u001B[0;36mwait\u001B[0;34m(object_list, timeout)\u001B[0m\n\u001B[1;32m    945\u001B[0m     deadline \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic() \u001B[38;5;241m+\u001B[39m timeout\n\u001B[1;32m    947\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 948\u001B[0m     ready \u001B[38;5;241m=\u001B[39m selector\u001B[38;5;241m.\u001B[39mselect(timeout)\n\u001B[1;32m    949\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ready:\n\u001B[1;32m    950\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [key\u001B[38;5;241m.\u001B[39mfileobj \u001B[38;5;28;01mfor\u001B[39;00m (key, events) \u001B[38;5;129;01min\u001B[39;00m ready]\n",
      "File \u001B[0;32m~/miniconda3/envs/mi-env/lib/python3.11/selectors.py:415\u001B[0m, in \u001B[0;36m_PollLikeSelector.select\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    413\u001B[0m ready \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    414\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 415\u001B[0m     fd_event_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_selector\u001B[38;5;241m.\u001B[39mpoll(timeout)\n\u001B[1;32m    416\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mInterruptedError\u001B[39;00m:\n\u001B[1;32m    417\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ready\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T10:08:25.309506Z",
     "start_time": "2024-07-05T10:08:25.307214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(LOWER_BOUND_WINDOW_HRCT)\n",
    "print(UPPER_BOUND_WINDOW_HRCT)"
   ],
   "id": "bdf317b6cbe36895",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1400\n",
      "100\n"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-05T08:24:00.625031Z",
     "start_time": "2024-07-05T08:24:00.566084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def t():\n",
    "    return monai.transforms.Compose(\n",
    "        [\n",
    "            # monai.transforms.LoadImaged(keys=('img', 'mask'), image_only=True, ensure_channel_first=True),\n",
    "            monai.transforms.Orientationd(keys=('img', 'mask'), axcodes=\"PLI\"),\n",
    "            monai.transforms.ScaleIntensityRanged(keys=('img',), a_min=LOWER_BOUND_WINDOW_HRCT,\n",
    "                                            a_max=UPPER_BOUND_WINDOW_HRCT, b_min=0.0, b_max=1.0, clip=True),\n",
    "            monai.transforms.ToTensord(keys=(\"img\", \"mask\")),\n",
    "        ]\n",
    "    )\n",
    "sample_data = {\n",
    "    'img': np.random.randint(-2000, 2000, (2, 128, 128, 128)),  # Example volume\n",
    "    'mask': np.random.randint(0, 2, (2, 128, 128, 128))         # Example mask\n",
    "}\n",
    "\n",
    "transforms_pipeline = t()\n",
    "transformed_data = transforms_pipeline(sample_data)\n",
    "\n",
    "# Print some statistics of the normalized volume to verify\n",
    "print(f\"Min value (img): {transformed_data['img'].min()}\")\n",
    "print(f\"Max value (img): {transformed_data['img'].max()}\")\n",
    "print(f\"Mean value (img): {transformed_data['img'].mean()}\")"
   ],
   "id": "77b155b09381829f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min value (img): 0.0\n",
      "Max value (img): 1.0\n",
      "Mean value (img): 0.6622612476348877\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T16:09:30.126287Z",
     "start_time": "2024-07-11T16:09:30.110637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import nibabel and load an image from data_paths and explore the min and max value of each image\n",
    "import nibabel as nib\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "min = [100000,1000000,100000]\n",
    "for i in range(len(data_dicts)):\n",
    "    f = nib.load(data_dicts[i][\"img\"])\n",
    "    print(f.header[\"srow_y\"][1])\n",
    "    if min[0] > abs(f.header[\"srow_x\"][0]):\n",
    "        min[0] = abs(f.header[\"srow_x\"][0])\n",
    "    if min[1] > abs(f.header[\"srow_y\"][1]):\n",
    "        min[1] = abs(f.header[\"srow_y\"][1])\n",
    "    if min[2] > abs(f.header[\"srow_z\"][2]):\n",
    "        min[2] = abs(f.header[\"srow_z\"][2])\n",
    "print(min)"
   ],
   "id": "34e3074c79b4fcb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.683594\n",
      "0.683594\n",
      "0.683594\n",
      "0.683594\n",
      "0.683594\n",
      "0.683594\n",
      "0.683594\n",
      "0.683594\n",
      "0.683594\n",
      "0.683594\n",
      "[0.683594, 0.683594, 1.0]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "662cdf21336c85a7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T16:09:44.356124Z",
     "start_time": "2024-07-11T16:09:36.413344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i, data in enumerate(radiopaedia_loader):\n",
    "    print(data[\"img_meta_dict\"][\"affine\"])"
   ],
   "id": "44d23444bf86a1f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[  -0.6836,   -0.0000,    0.0000,  159.0000],\n",
      "         [  -0.0000,    0.6836,    0.0000,  174.0000],\n",
      "         [   0.0000,    0.0000,    6.0000, -228.0000],\n",
      "         [   0.0000,    0.0000,    0.0000,    1.0000]]], dtype=torch.float64)\n",
      "tensor([[[  -0.6836,   -0.0000,    0.0000,  159.0000],\n",
      "         [  -0.0000,    0.6836,    0.0000,  174.0000],\n",
      "         [   0.0000,    0.0000,    6.0000, -390.0000],\n",
      "         [   0.0000,    0.0000,    0.0000,    1.0000]]], dtype=torch.float64)\n",
      "tensor([[[  -0.6836,   -0.0000,    0.0000,  159.0000],\n",
      "         [  -0.0000,    0.6836,    0.0000,  174.0000],\n",
      "         [   0.0000,    0.0000,    6.0000, -246.0000],\n",
      "         [   0.0000,    0.0000,    0.0000,    1.0000]]], dtype=torch.float64)\n",
      "tensor([[[  -0.6836,   -0.0000,    0.0000,  159.0000],\n",
      "         [  -0.0000,    0.6836,    0.0000,  174.0000],\n",
      "         [   0.0000,    0.0000,    6.0000, -264.0000],\n",
      "         [   0.0000,    0.0000,    0.0000,    1.0000]]], dtype=torch.float64)\n",
      "tensor([[[  -0.6836,   -0.0000,    0.0000,  159.0000],\n",
      "         [  -0.0000,    0.6836,    0.0000,  174.0000],\n",
      "         [   0.0000,    0.0000,    1.0000, -417.0000],\n",
      "         [   0.0000,    0.0000,    0.0000,    1.0000]]], dtype=torch.float64)\n",
      "tensor([[[  -0.6836,   -0.0000,    0.0000,  159.0000],\n",
      "         [  -0.0000,    0.6836,    0.0000,  174.0000],\n",
      "         [   0.0000,    0.0000,    6.0000, -264.0000],\n",
      "         [   0.0000,    0.0000,    0.0000,    1.0000]]], dtype=torch.float64)\n",
      "tensor([[[  -0.6836,   -0.0000,    0.0000,  159.0000],\n",
      "         [  -0.0000,    0.6836,    0.0000,  174.0000],\n",
      "         [   0.0000,    0.0000,    2.0000, -218.0000],\n",
      "         [   0.0000,    0.0000,    0.0000,    1.0000]]], dtype=torch.float64)\n",
      "tensor([[[  -0.6836,   -0.0000,    0.0000,  159.0000],\n",
      "         [  -0.0000,    0.6836,    0.0000,  174.0000],\n",
      "         [   0.0000,    0.0000,    6.0000, -228.0000],\n",
      "         [   0.0000,    0.0000,    0.0000,    1.0000]]], dtype=torch.float64)\n",
      "tensor([[[  -0.6836,   -0.0000,    0.0000,  159.0000],\n",
      "         [  -0.0000,    0.6836,    0.0000,  174.0000],\n",
      "         [   0.0000,    0.0000,    4.0000, -368.0000],\n",
      "         [   0.0000,    0.0000,    0.0000,    1.0000]]], dtype=torch.float64)\n",
      "tensor([[[  -0.6836,   -0.0000,    0.0000,  159.0000],\n",
      "         [  -0.0000,    0.6836,    0.0000,  174.0000],\n",
      "         [   0.0000,    0.0000,    6.0000, -246.0000],\n",
      "         [   0.0000,    0.0000,    0.0000,    1.0000]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7a8d5204fabcd7cf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
